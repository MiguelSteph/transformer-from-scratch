{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34bc1b5",
   "metadata": {},
   "source": [
    "# Install and import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f18be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.5/494.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U grain clu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798e1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jax Device count: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"]=\"platform\"\n",
    "\n",
    "'''\n",
    "    Uncomment the line bellow to simulate 8 devices when running on CPU.\n",
    "'''\n",
    "flags = os.environ.get(\"XLA_FLAGS\", \"\")\n",
    "flags += \" --xla_force_host_platform_device_count=8\"  # Simulate 8 devices\n",
    "os.environ[\"XLA_FLAGS\"] = flags\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax.training.common_utils import shard, shard_prng_key, get_metrics\n",
    "import optax\n",
    "import numpy as np\n",
    "import grain.python as grain\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ml_collections\n",
    "from tqdm.auto import tqdm\n",
    "from clu import metric_writers\n",
    "import orbax.checkpoint as ocp\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import nltk\n",
    "\n",
    "import pathlib\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "prng_main_key = jax.random.key(18)\n",
    "\n",
    "print(f\"Jax Device count: {jax.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38557273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47644a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom files\n",
    "\n",
    "# Download the code to the current working directory\n",
    "REPO_NAME = 'transformer-from-scratch'\n",
    "if not os.path.isdir(REPO_NAME):\n",
    "    !git clone https://github.com/MiguelSteph/transformer-from-scratch.git\n",
    "\n",
    "%run 'transformer-from-scratch/configs/configs.py'\n",
    "%run 'transformer-from-scratch/dataset_utils.py'\n",
    "%run 'transformer-from-scratch/tokenizer.py'\n",
    "%run 'transformer-from-scratch/models.py'\n",
    "%run 'transformer-from-scratch/train_and_eval_utils.py'\n",
    "\n",
    "\n",
    "config = get_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd51aa9",
   "metadata": {},
   "source": [
    "# Download the dataset\n",
    "We will use the french to english dataset.\n",
    "It can be downloaded at https://storage.googleapis.com/download.tensorflow.org/data/fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d72f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed2473",
   "metadata": {},
   "source": [
    "# Build BPE tokenizer\n",
    "In the first version of the project, I used the tiktoken tokenizer. Since we have a small dataset, I noticed the the number of token is too much and the model has some issue to increase its accuracy.\n",
    "I switched to creating a custom tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87550334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer is already built.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(config.trg_tokenizer_path + '/vocab.json'):\n",
    "    build_and_save_tokenizer(config)\n",
    "else:\n",
    "    print(\"Tokenizer is already built.\")\n",
    "\n",
    "# Load saved tokenizer\n",
    "fr_tokenizer = ByteLevelBPETokenizer(config.trg_tokenizer_path + '/vocab.json', config.trg_tokenizer_path + '/merges.txt')\n",
    "en_tokenizer = ByteLevelBPETokenizer(config.src_tokenizer_path + '/vocab.json', config.src_tokenizer_path + '/merges.txt')\n",
    "fr_tokenizer.add_special_tokens(config.tokenizer_special_tokens)\n",
    "en_tokenizer.add_special_tokens(config.tokenizer_special_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463f4fe",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "We will explore the following aspect of the dataset:\n",
    "* overall number of sample in the dataset\n",
    "* Number of unique sentences both in english and french\n",
    "* Number of tokens distribution both in english and french\n",
    "\n",
    "The exploration has the following two goals:\n",
    "* Determine the correct max sequence length for the model\n",
    "* Better slit the dataset into train, validation and test sets. We don't want to include the same sentences into training and validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0065468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size is 167130\n",
      "Number of unique french sentences is 158527 which is 94%\n",
      "Number of unique english sentences is 116830 which is 69%\n",
      "Max token length for french sentences is 90\n",
      "Max token length for english sentences is 69\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANzxJREFUeJzt3X9cV/X9//87P+SHKC9Ek5dMVNqYP+ZvScTMapFYrvco28SYWTFdDUwkf6YhM42kWWmazG1Nt3SZn6UrNIpwylJCxJg/UnJFqdkL3EXhNTF+BOf7x76ciy+1FH0Z4rldL5dzufg6z8freR6Hs+1133mdc14ehmEYAgAAsCDPlm4AAACgpRCEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZRGEAACAZXm3dAPXssbGRh0/flzt27eXh4dHS7cDAAAugWEY+u9//6vQ0FB5en77OR+C0Lc4fvy4wsLCWroNAABwGY4ePaquXbt+aw1B6Fu0b99e0v/+kIGBgS3cDQAAuBROp1NhYWHm5/i3IQh9i6avwwIDAwlCAAC0MpdyWQsXSwMAAMsiCAEAAMsiCAEAAMviGiEAAJqpoaFB9fX1Ld2GpbVp00ZeXl5XPA9BCACAZjh9+rSOHTsmwzBauhVL8/DwUNeuXdWuXbsrmocgBADAJWpoaNCxY8fUtm1b3XDDDTxst4UYhqETJ07o2LFjioiIuKIzQwQhAAAuUX19vQzD0A033CB/f/+WbsfSbrjhBn322Weqr6+/oiDExdIAADQTZ4JanruOAUEIAABYFkEIAAC4xUMPPaS4uDjz9W233aaUlJRLem9zat2Ja4QAALhS6enX9/Yu0xtvvKE2bdq0dBvfqtlnhPLz83XPPfcoNDRUHh4e2rRp0zfWPvroo/Lw8NCLL77osv7kyZNKSEhQYGCggoKClJiYqNOnT7vU7N27V7fccov8/PwUFhamzMzM8+bfsGGDevXqJT8/P/Xr109btmxxGTcMQ2lpaerSpYv8/f0VExOjw4cPN3eXAQDAZQgODr6kHz5tSc0OQtXV1RowYIBWrFjxrXUbN27UBx98oNDQ0PPGEhISdODAAeXm5io7O1v5+fmaPHmyOe50OjVq1Ch1795dxcXFeu6555Senq5Vq1aZNTt37tT48eOVmJioDz/8UHFxcYqLi9P+/fvNmszMTC1btkxZWVkqLCxUQECAYmNjVVNT09zdBgCgVWtsbFRGRobCw8Pl7++vAQMG6P/9v/8nSdq2bZs8PDyUl5enyMhItW3bVsOHD1dpaanLHAsXLlTnzp3Vvn17/fKXv9Ts2bM1cODAb9zmuV93vfzyy4qIiJCfn59CQkJ0//33n9fjzJkzFRwcLLvdrvTv4MxXs4PQXXfdpYULF+ree+/9xpovvvhCU6ZM0dq1a887JXbw4EHl5OToD3/4g6KiojRixAi99NJLeu2113T8+HFJ0tq1a1VXV6dXXnlFP/rRjxQfH6/HH39czz//vDnP0qVLNXr0aM2YMUO9e/fW008/rcGDB2v58uWS/nc26MUXX9S8efP005/+VP3799ef//xnHT9+/FvPYgEAcD3KyMjQn//8Z2VlZenAgQOaNm2afvGLX2j79u1mzdy5c7VkyRLt3r1b3t7eeuSRR8yxtWvXatGiRVq8eLGKi4vVrVs3rVy58pK3v3v3bj3++ONasGCBSktLlZOTo5EjR7rUrFmzRgEBASosLFRmZqYWLFig3NzcK9/5b+H2a4QaGxs1YcIEzZgxQz/60Y/OGy8oKFBQUJAiIyPNdTExMfL09FRhYaHuvfdeFRQUaOTIkfLx8TFrYmNjtXjxYp06dUodOnRQQUGBUlNTXeaOjY01Q05ZWZkcDodiYmLMcZvNpqioKBUUFCg+Pv683mpra1VbW2u+djqdl/13uCTuSrqt5LtiAEDLqK2t1TPPPKP33ntP0dHRkqQbb7xR77//vn73u9+Z38osWrRIt956qyRp9uzZGjNmjGpqauTn56eXXnpJiYmJevjhhyVJaWlpevfdd8+7tOWbHDlyRAEBAfrJT36i9u3bq3v37ho0aJBLTf/+/TV//nxJUkREhJYvX668vDzdeeedbvk7XIjb7xpbvHixvL299fjjj19w3OFwqHPnzi7rvL29FRwcLIfDYdaEhIS41DS9vljN2eNnv+9CNefKyMiQzWYzl7CwsIvuLwAA17p///vfOnPmjO688061a9fOXP785z/rk08+Mev69+9v/rtLly6SpIqKCklSaWmphg4d6jLvua+/zZ133qnu3bvrxhtv1IQJE7R27VqdOXPGpebs7Tf10LT9q8WtZ4SKi4u1dOlS7dmzp1U+bGrOnDkuZ5mcTidhCADQ6jWdtdm8ebO+973vuYz5+vqaYejsy1maPscbGxvd0kP79u21Z88ebdu2Te+++67S0tKUnp6uoqIiBQUFnbf9ph7ctf1v4tYzQv/85z9VUVGhbt26ydvbW97e3vr888/1xBNPqEePHpIku91+Xrr7+uuvdfLkSdntdrOmvLzcpabp9cVqzh4/+30XqjmXr6+vAgMDXRYAAFq7Pn36yNfXV0eOHNEPfvADl+VS/w9/z549VVRU5LLu3NcX4+3trZiYGGVmZmrv3r367LPPtHXr1mbN4W5uPSM0YcIEl2typP9dtzNhwgTzO8Xo6GhVVlaquLhYQ4YMkSRt3bpVjY2NioqKMmvmzp2r+vp6Mx3m5uaqZ8+e6tChg1mTl5fncjV6bm6u+d1neHi47Ha78vLyzCvanU6nCgsL9dhjj7lztwEAuKa1b99e06dP17Rp09TY2KgRI0aoqqpKO3bsUGBgoLp3737ROaZMmaJJkyYpMjJSw4cP1/r167V3717deOONl9RDdna2Pv30U40cOVIdOnTQli1b1NjYqJ49e17p7l2RZgeh06dP69///rf5uqysTCUlJQoODla3bt3UsWNHl/o2bdrIbrebO9q7d2+NHj1akyZNUlZWlurr65WcnKz4+HjzVvsHHnhAv/nNb5SYmKhZs2Zp//79Wrp0qV544QVz3qlTp+rWW2/VkiVLNGbMGL322mvavXu3eYu9h4eHUlJStHDhQkVERCg8PFxPPfWUQkNDXZ56CQCAFTz99NO64YYblJGRoU8//VRBQUEaPHiwnnzyyUv6+ikhIUGffvqppk+frpqaGv385z/XQw89pF27dl3S9oOCgvTGG28oPT1dNTU1ioiI0F//+tcL3lj1XfIwDMNozhu2bdum22+//bz1EydO1OrVq89b36NHD6WkpLicuTl58qSSk5P11ltvydPTU2PHjtWyZcvUrl07s2bv3r1KSkpSUVGROnXqpClTpmjWrFkuc2/YsEHz5s3TZ599poiICGVmZuruu+82xw3D0Pz587Vq1SpVVlZqxIgRevnll/XDH/7wkvbV6XTKZrOpqqrq6nxNxl1jANCq1NTUqKysTOHh4fLz82vpdlrcnXfeKbvdrr/85S/f+ba/7Vg05/O72UHISghCAICzWTkInTlzRllZWYqNjZWXl5f++te/ms/5OfeymO+Cu4IQvzUGAAAuysPDQ1u2bNGiRYtUU1Ojnj176m9/+1uLhCB3IggBAICL8vf313vvvdfSbbid2x+oCAAA0FoQhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAuM4ZhqHJkycrODhYHh4eKikpaZE+Vq9ebf7S/LWC5wgBAHCFvusH/Dd3ezk5OVq9erW2bdumG2+8UZ06dboqfbVGBCEAAK5zn3zyibp06aLhw4dfcLyurk4+Pj7fcVfXBr4aAwDgOvbQQw9pypQpOnLkiDw8PNSjRw/ddtttSk5OVkpKijp16qTY2FhJ0v79+3XXXXepXbt2CgkJ0YQJE/Sf//zHnOu2227T448/rpkzZyo4OFh2u13p55yeqqys1K9+9SuFhITIz89Pffv2VXZ2tkvNO++8o969e6tdu3YaPXq0vvzyy6v+d/gmBCEAAK5jS5cu1YIFC9S1a1d9+eWXKioqkiStWbNGPj4+2rFjh7KyslRZWakf//jHGjRokHbv3q2cnByVl5fr5z//uct8a9asUUBAgAoLC5WZmWn+8KokNTY26q677tKOHTv06quv6qOPPtKzzz4rLy8v8/1nzpzRb3/7W/3lL39Rfn6+jhw5ounTp393f5Bz8NUYAADXMZvNpvbt28vLy0t2u91cHxERoczMTPP1woULNWjQID3zzDPmuldeeUVhYWH6+OOP9cMf/lCS1L9/f82fP9+cY/ny5crLy9Odd96p9957T7t27dLBgwfN+htvvNGln/r6emVlZen73/++JCk5OVkLFiy4Ojt/CQhCAABY0JAhQ1xe/+tf/9I//vEPtWvX7rzaTz75xCUIna1Lly6qqKiQJJWUlKhr165m7YW0bdvWDEHnvr8lEIQAALCggIAAl9enT5/WPffco8WLF59X26VLF/Pfbdq0cRnz8PBQY2OjpP/9Qv3FXOj9hmFcct/uRhACAAAaPHiw/va3v6lHjx7y9r68eNC/f38dO3bM5au0ax0XSwMAACUlJenkyZMaP368ioqK9Mknn+idd97Rww8/rIaGhkua49Zbb9XIkSM1duxY5ebmqqysTG+//bZycnKucveXjyAEAAAUGhqqHTt2qKGhQaNGjVK/fv2UkpKioKAgeXpeelz429/+pptuuknjx49Xnz59NHPmzEsOUi3Bw2jJL+aucU6nUzabTVVVVQoMDHT/Btz1KNLv+pGmAGBRNTU1KisrU3h4uPz8/Fq6HUv7tmPRnM9vzggBAADLIggBAADLIggBAADLIggBAADLIggBAADLIggBANBM3HDd8tx1DAhCAABcoqZfUa+rq2vhTtB0DM7+ZfvLwU9sAABwiby9vdW2bVudOHFCbdq0adaDBuE+jY2NOnHihNq2bXvZPwfShCAEAMAl8vDwUJcuXVRWVqbPP/+8pduxNE9PT3Xr1k0eHh5XNA9BCACAZvDx8VFERARfj7UwHx8ft5yRIwgBANBMnp6e/MTGdYIvNwEAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGURhAAAgGU1Owjl5+frnnvuUWhoqDw8PLRp0yZzrL6+XrNmzVK/fv0UEBCg0NBQPfjggzp+/LjLHCdPnlRCQoICAwMVFBSkxMREnT592qVm7969uuWWW+Tn56ewsDBlZmae18uGDRvUq1cv+fn5qV+/ftqyZYvLuGEYSktLU5cuXeTv76+YmBgdPny4ubsMAACuU80OQtXV1RowYIBWrFhx3tiZM2e0Z88ePfXUU9qzZ4/eeOMNlZaW6v/+7/9c6hISEnTgwAHl5uYqOztb+fn5mjx5sjnudDo1atQode/eXcXFxXruueeUnp6uVatWmTU7d+7U+PHjlZiYqA8//FBxcXGKi4vT/v37zZrMzEwtW7ZMWVlZKiwsVEBAgGJjY1VTU9Pc3QYAANchD8MwjMt+s4eHNm7cqLi4uG+sKSoq0tChQ/X555+rW7duOnjwoPr06aOioiJFRkZKknJycnT33Xfr2LFjCg0N1cqVKzV37lw5HA75+PhIkmbPnq1Nmzbp0KFDkqRx48apurpa2dnZ5raGDRumgQMHKisrS4ZhKDQ0VE888YSmT58uSaqqqlJISIhWr16t+Pj4i+6f0+mUzWZTVVWVAgMDL/fP9M3S06+teQAAuA405/P7ql8jVFVVJQ8PDwUFBUmSCgoKFBQUZIYgSYqJiZGnp6cKCwvNmpEjR5ohSJJiY2NVWlqqU6dOmTUxMTEu24qNjVVBQYEkqaysTA6Hw6XGZrMpKirKrDlXbW2tnE6nywIAAK5fVzUI1dTUaNasWRo/fryZyBwOhzp37uxS5+3treDgYDkcDrMmJCTEpabp9cVqzh4/+30XqjlXRkaGbDabuYSFhTV7nwEAQOtx1YJQfX29fv7zn8swDK1cufJqbcat5syZo6qqKnM5evRoS7cEAACuIu+rMWlTCPr888+1detWl+/n7Ha7KioqXOq//vprnTx5Una73awpLy93qWl6fbGas8eb1nXp0sWlZuDAgRfs29fXV76+vs3dXQAA0Eq5/YxQUwg6fPiw3nvvPXXs2NFlPDo6WpWVlSouLjbXbd26VY2NjYqKijJr8vPzVV9fb9bk5uaqZ8+e6tChg1mTl5fnMndubq6io6MlSeHh4bLb7S41TqdThYWFZg0AALC2Zgeh06dPq6SkRCUlJZL+d1FySUmJjhw5ovr6et1///3avXu31q5dq4aGBjkcDjkcDtXV1UmSevfurdGjR2vSpEnatWuXduzYoeTkZMXHxys0NFSS9MADD8jHx0eJiYk6cOCA1q9fr6VLlyo1NdXsY+rUqcrJydGSJUt06NAhpaena/fu3UpOTpb0vzvaUlJStHDhQr355pvat2+fHnzwQYWGhn7rXW4AAMA6mn37/LZt23T77beft37ixIlKT09XeHj4Bd/3j3/8Q7fddpuk/z1QMTk5WW+99ZY8PT01duxYLVu2TO3atTPr9+7dq6SkJBUVFalTp06aMmWKZs2a5TLnhg0bNG/ePH322WeKiIhQZmam7r77bnPcMAzNnz9fq1atUmVlpUaMGKGXX35ZP/zhDy9pX7l9HgCA1qc5n99X9Byh6x1BCACA1ueaeo4QAADAtYogBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALMu7pRvAlUtPvzbnAgDgWscZIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFnNDkL5+fm65557FBoaKg8PD23atMll3DAMpaWlqUuXLvL391dMTIwOHz7sUnPy5EklJCQoMDBQQUFBSkxM1OnTp11q9u7dq1tuuUV+fn4KCwtTZmbmeb1s2LBBvXr1kp+fn/r166ctW7Y0uxcAAGBdzQ5C1dXVGjBggFasWHHB8czMTC1btkxZWVkqLCxUQECAYmNjVVNTY9YkJCTowIEDys3NVXZ2tvLz8zV58mRz3Ol0atSoUerevbuKi4v13HPPKT09XatWrTJrdu7cqfHjxysxMVEffvih4uLiFBcXp/379zerFwAAYF0ehmEYl/1mDw9t3LhRcXFxkv53BiY0NFRPPPGEpk+fLkmqqqpSSEiIVq9erfj4eB08eFB9+vRRUVGRIiMjJUk5OTm6++67dezYMYWGhmrlypWaO3euHA6HfHx8JEmzZ8/Wpk2bdOjQIUnSuHHjVF1drezsbLOfYcOGaeDAgcrKyrqkXi7G6XTKZrOpqqpKgYGBl/tn+mZueoxzutwzj8STpQEArV9zPr/deo1QWVmZHA6HYmJizHU2m01RUVEqKCiQJBUUFCgoKMgMQZIUExMjT09PFRYWmjUjR440Q5AkxcbGqrS0VKdOnTJrzt5OU03Tdi6ll3PV1tbK6XS6LAAA4Prl1iDkcDgkSSEhIS7rQ0JCzDGHw6HOnTu7jHt7eys4ONil5kJznL2Nb6o5e/xivZwrIyNDNpvNXMLCwi5hrwEAQGvFXWNnmTNnjqqqqszl6NGjLd0SAAC4itwahOx2uySpvLzcZX15ebk5ZrfbVVFR4TL+9ddf6+TJky41F5rj7G18U83Z4xfr5Vy+vr4KDAx0WQAAwPXLrUEoPDxcdrtdeXl55jqn06nCwkJFR0dLkqKjo1VZWani4mKzZuvWrWpsbFRUVJRZk5+fr/r6erMmNzdXPXv2VIcOHcyas7fTVNO0nUvpBQAAWFuzg9Dp06dVUlKikpISSf+7KLmkpERHjhyRh4eHUlJStHDhQr355pvat2+fHnzwQYWGhpp3lvXu3VujR4/WpEmTtGvXLu3YsUPJycmKj49XaGioJOmBBx6Qj4+PEhMTdeDAAa1fv15Lly5Vamqq2cfUqVOVk5OjJUuW6NChQ0pPT9fu3buVnJwsSZfUCwAAsDbv5r5h9+7duv32283XTeFk4sSJWr16tWbOnKnq6mpNnjxZlZWVGjFihHJycuTn52e+Z+3atUpOTtYdd9whT09PjR07VsuWLTPHbTab3n33XSUlJWnIkCHq1KmT0tLSXJ41NHz4cK1bt07z5s3Tk08+qYiICG3atEl9+/Y1ay6lFwAAYF1X9Byh6x3PEQIAoPVpsecIAQAAtCYEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFkEIQAAYFluD0INDQ166qmnFB4eLn9/f33/+9/X008/LcMwzBrDMJSWlqYuXbrI399fMTExOnz4sMs8J0+eVEJCggIDAxUUFKTExESdPn3apWbv3r265ZZb5Ofnp7CwMGVmZp7Xz4YNG9SrVy/5+fmpX79+2rJli7t3GQAAtFJuD0KLFy/WypUrtXz5ch08eFCLFy9WZmamXnrpJbMmMzNTy5YtU1ZWlgoLCxUQEKDY2FjV1NSYNQkJCTpw4IByc3OVnZ2t/Px8TZ482Rx3Op0aNWqUunfvruLiYj333HNKT0/XqlWrzJqdO3dq/PjxSkxM1Icffqi4uDjFxcVp//797t5tAADQCnkYZ5+qcYOf/OQnCgkJ0R//+Edz3dixY+Xv769XX31VhmEoNDRUTzzxhKZPny5JqqqqUkhIiFavXq34+HgdPHhQffr0UVFRkSIjIyVJOTk5uvvuu3Xs2DGFhoZq5cqVmjt3rhwOh3x8fCRJs2fP1qZNm3To0CFJ0rhx41RdXa3s7Gyzl2HDhmngwIHKysq66L44nU7ZbDZVVVUpMDDQbX8jU3q6e6aRe+aR3NYSAAAtpjmf324/IzR8+HDl5eXp448/liT961//0vvvv6+77rpLklRWViaHw6GYmBjzPTabTVFRUSooKJAkFRQUKCgoyAxBkhQTEyNPT08VFhaaNSNHjjRDkCTFxsaqtLRUp06dMmvO3k5TTdN2AACAtXm7e8LZs2fL6XSqV69e8vLyUkNDgxYtWqSEhARJksPhkCSFhIS4vC8kJMQcczgc6ty5s2uj3t4KDg52qQkPDz9vjqaxDh06yOFwfOt2zlVbW6va2lrztdPpbNa+AwCA1sXtZ4Ref/11rV27VuvWrdOePXu0Zs0a/fa3v9WaNWvcvSm3y8jIkM1mM5ewsLCWbgkAAFxFbg9CM2bM0OzZsxUfH69+/fppwoQJmjZtmjIyMiRJdrtdklReXu7yvvLycnPMbreroqLCZfzrr7/WyZMnXWouNMfZ2/immqbxc82ZM0dVVVXmcvTo0WbvPwAAaD3cHoTOnDkjT0/Xab28vNTY2ChJCg8Pl91uV15enjnudDpVWFio6OhoSVJ0dLQqKytVXFxs1mzdulWNjY2Kiooya/Lz81VfX2/W5ObmqmfPnurQoYNZc/Z2mmqatnMuX19fBQYGuiwAAOD65fYgdM8992jRokXavHmzPvvsM23cuFHPP/+87r33XkmSh4eHUlJStHDhQr355pvat2+fHnzwQYWGhiouLk6S1Lt3b40ePVqTJk3Srl27tGPHDiUnJys+Pl6hoaGSpAceeEA+Pj5KTEzUgQMHtH79ei1dulSpqalmL1OnTlVOTo6WLFmiQ4cOKT09Xbt371ZycrK7dxsAALRCbr9Y+qWXXtJTTz2lX//616qoqFBoaKh+9atfKS0tzayZOXOmqqurNXnyZFVWVmrEiBHKycmRn5+fWbN27VolJyfrjjvukKenp8aOHatly5aZ4zabTe+++66SkpI0ZMgQderUSWlpaS7PGho+fLjWrVunefPm6cknn1RERIQ2bdqkvn37unu3AQBAK+T25whdT3iOEAAArU+LPkcIAACgtSAIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAyyIIAQAAy7oqQeiLL77QL37xC3Xs2FH+/v7q16+fdu/ebY4bhqG0tDR16dJF/v7+iomJ0eHDh13mOHnypBISEhQYGKigoCAlJibq9OnTLjV79+7VLbfcIj8/P4WFhSkzM/O8XjZs2KBevXrJz89P/fr105YtW67GLgMAgFbI7UHo1KlTuvnmm9WmTRu9/fbb+uijj7RkyRJ16NDBrMnMzNSyZcuUlZWlwsJCBQQEKDY2VjU1NWZNQkKCDhw4oNzcXGVnZys/P1+TJ082x51Op0aNGqXu3buruLhYzz33nNLT07Vq1SqzZufOnRo/frwSExP14YcfKi4uTnFxcdq/f7+7dxsAALRCHoZhGO6ccPbs2dqxY4f++c9/XnDcMAyFhobqiSee0PTp0yVJVVVVCgkJ0erVqxUfH6+DBw+qT58+KioqUmRkpCQpJydHd999t44dO6bQ0FCtXLlSc+fOlcPhkI+Pj7ntTZs26dChQ5KkcePGqbq6WtnZ2eb2hw0bpoEDByorK+ui++J0OmWz2VRVVaXAwMAr+rtcUHq6e6aRe+aR3NYSAAAtpjmf324/I/Tmm28qMjJSP/vZz9S5c2cNGjRIv//9783xsrIyORwOxcTEmOtsNpuioqJUUFAgSSooKFBQUJAZgiQpJiZGnp6eKiwsNGtGjhxphiBJio2NVWlpqU6dOmXWnL2dppqm7ZyrtrZWTqfTZQEAANcvtwehTz/9VCtXrlRERITeeecdPfbYY3r88ce1Zs0aSZLD4ZAkhYSEuLwvJCTEHHM4HOrcubPLuLe3t4KDg11qLjTH2dv4ppqm8XNlZGTIZrOZS1hYWLP3HwAAtB5uD0KNjY0aPHiwnnnmGQ0aNEiTJ0/WpEmTLumrqJY2Z84cVVVVmcvRo0dbuiUAAHAVuT0IdenSRX369HFZ17t3bx05ckSSZLfbJUnl5eUuNeXl5eaY3W5XRUWFy/jXX3+tkydPutRcaI6zt/FNNU3j5/L19VVgYKDLAgAArl9uD0I333yzSktLXdZ9/PHH6t69uyQpPDxcdrtdeXl55rjT6VRhYaGio6MlSdHR0aqsrFRxcbFZs3XrVjU2NioqKsqsyc/PV319vVmTm5urnj17mneoRUdHu2ynqaZpOwAAwNrcHoSmTZumDz74QM8884z+/e9/a926dVq1apWSkpIkSR4eHkpJSdHChQv15ptvat++fXrwwQcVGhqquLg4Sf87gzR69GhNmjRJu3bt0o4dO5ScnKz4+HiFhoZKkh544AH5+PgoMTFRBw4c0Pr167V06VKlpqaavUydOlU5OTlasmSJDh06pPT0dO3evVvJycnu3m0AANAKebt7wptuukkbN27UnDlztGDBAoWHh+vFF19UQkKCWTNz5kxVV1dr8uTJqqys1IgRI5STkyM/Pz+zZu3atUpOTtYdd9whT09PjR07VsuWLTPHbTab3n33XSUlJWnIkCHq1KmT0tLSXJ41NHz4cK1bt07z5s3Tk08+qYiICG3atEl9+/Z1924DAIBWyO3PEbqe8Byhq8ud2+L5RwCAJi36HCEAAIDWgiAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAs66oHoWeffVYeHh5KSUkx19XU1CgpKUkdO3ZUu3btNHbsWJWXl7u878iRIxozZozatm2rzp07a8aMGfr6669darZt26bBgwfL19dXP/jBD7R69erztr9ixQr16NFDfn5+ioqK0q5du67GbgIAgFboqgahoqIi/e53v1P//v1d1k+bNk1vvfWWNmzYoO3bt+v48eO67777zPGGhgaNGTNGdXV12rlzp9asWaPVq1crLS3NrCkrK9OYMWN0++23q6SkRCkpKfrlL3+pd955x6xZv369UlNTNX/+fO3Zs0cDBgxQbGysKioqruZuAwCAVuKqBaHTp08rISFBv//979WhQwdzfVVVlf74xz/q+eef149//GMNGTJEf/rTn7Rz50598MEHkqR3331XH330kV599VUNHDhQd911l55++mmtWLFCdXV1kqSsrCyFh4dryZIl6t27t5KTk3X//ffrhRdeMLf1/PPPa9KkSXr44YfVp08fZWVlqW3btnrllVeu1m4DAIBW5KoFoaSkJI0ZM0YxMTEu64uLi1VfX++yvlevXurWrZsKCgokSQUFBerXr59CQkLMmtjYWDmdTh04cMCsOXfu2NhYc466ujoVFxe71Hh6eiomJsasOVdtba2cTqfLAgAArl/eV2PS1157TXv27FFRUdF5Yw6HQz4+PgoKCnJZHxISIofDYdacHYKaxpvGvq3G6XTqq6++0qlTp9TQ0HDBmkOHDl2w74yMDP3mN7+59B0FAACtmtvPCB09elRTp07V2rVr5efn5+7pr6o5c+aoqqrKXI4ePdrSLQEAgKvI7UGouLhYFRUVGjx4sLy9veXt7a3t27dr2bJl8vb2VkhIiOrq6lRZWenyvvLyctntdkmS3W4/7y6yptcXqwkMDJS/v786deokLy+vC9Y0zXEuX19fBQYGuiwAAOD65fYgdMcdd2jfvn0qKSkxl8jISCUkJJj/btOmjfLy8sz3lJaW6siRI4qOjpYkRUdHa9++fS53d+Xm5iowMFB9+vQxa86eo6mmaQ4fHx8NGTLEpaaxsVF5eXlmDQAAsDa3XyPUvn179e3b12VdQECAOnbsaK5PTExUamqqgoODFRgYqClTpig6OlrDhg2TJI0aNUp9+vTRhAkTlJmZKYfDoXnz5ikpKUm+vr6SpEcffVTLly/XzJkz9cgjj2jr1q16/fXXtXnzZnO7qampmjhxoiIjIzV06FC9+OKLqq6u1sMPP+zu3QYAAK3QVblY+mJeeOEFeXp6auzYsaqtrVVsbKxefvllc9zLy0vZ2dl67LHHFB0drYCAAE2cOFELFiwwa8LDw7V582ZNmzZNS5cuVdeuXfWHP/xBsbGxZs24ceN04sQJpaWlyeFwaODAgcrJyTnvAmoAAGBNHoZhGC3dxLXK6XTKZrOpqqrq6lwvlJ7unmnknnkkt7X0nW/ru+wbAHBta87nN781BgAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALIsgBAAALMu7pRtAK5Se7q6J3DQPAACXhzNCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAsghCAADAstwehDIyMnTTTTepffv26ty5s+Li4lRaWupSU1NTo6SkJHXs2FHt2rXT2LFjVV5e7lJz5MgRjRkzRm3btlXnzp01Y8YMff311y4127Zt0+DBg+Xr66sf/OAHWr169Xn9rFixQj169JCfn5+ioqK0a9cud+8yAABopdwehLZv366kpCR98MEHys3NVX19vUaNGqXq6mqzZtq0aXrrrbe0YcMGbd++XcePH9d9991njjc0NGjMmDGqq6vTzp07tWbNGq1evVppaWlmTVlZmcaMGaPbb79dJSUlSklJ0S9/+Uu98847Zs369euVmpqq+fPna8+ePRowYIBiY2NVUVHh7t0GAACtkIdhGMbV3MCJEyfUuXNnbd++XSNHjlRVVZVuuOEGrVu3Tvfff78k6dChQ+rdu7cKCgo0bNgwvf322/rJT36i48ePKyQkRJKUlZWlWbNm6cSJE/Lx8dGsWbO0efNm7d+/39xWfHy8KisrlZOTI0mKiorSTTfdpOXLl0uSGhsbFRYWpilTpmj27NkX7d3pdMpms6mqqkqBgYHu/tO47Te70t34m12X1FJr7RsAYAnN+fy+6tcIVVVVSZKCg4MlScXFxaqvr1dMTIxZ06tXL3Xr1k0FBQWSpIKCAvXr188MQZIUGxsrp9OpAwcOmDVnz9FU0zRHXV2diouLXWo8PT0VExNj1pyrtrZWTqfTZQEAANevqxqEGhsblZKSoptvvll9+/aVJDkcDvn4+CgoKMilNiQkRA6Hw6w5OwQ1jTeNfVuN0+nUV199pf/85z9qaGi4YE3THOfKyMiQzWYzl7CwsMvbcQAA0Cpc1SCUlJSk/fv367XXXruam3GbOXPmqKqqylyOHj3a0i0BAICryPtqTZycnKzs7Gzl5+era9eu5nq73a66ujpVVla6nBUqLy+X3W43a869u6vprrKza86906y8vFyBgYHy9/eXl5eXvLy8LljTNMe5fH195evre3k7DAAAWh23nxEyDEPJycnauHGjtm7dqvDwcJfxIUOGqE2bNsrLyzPXlZaW6siRI4qOjpYkRUdHa9++fS53d+Xm5iowMFB9+vQxa86eo6mmaQ4fHx8NGTLEpaaxsVF5eXlmDQAAsDa3nxFKSkrSunXr9Pe//13t27c3r8ex2Wzy9/eXzWZTYmKiUlNTFRwcrMDAQE2ZMkXR0dEaNmyYJGnUqFHq06ePJkyYoMzMTDkcDs2bN09JSUnmGZtHH31Uy5cv18yZM/XII49o69atev3117V582azl9TUVE2cOFGRkZEaOnSoXnzxRVVXV+vhhx92924DAIBWyO1BaOXKlZKk2267zWX9n/70Jz300EOSpBdeeEGenp4aO3asamtrFRsbq5dfftms9fLyUnZ2th577DFFR0crICBAEydO1IIFC8ya8PBwbd68WdOmTdPSpUvVtWtX/eEPf1BsbKxZM27cOJ04cUJpaWlyOBwaOHCgcnJyzruAGgAAWNNVf45Qa8ZzhK6k6BKm4TlCAICr4Jp6jhAAAMC1iiAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsiyAEAAAsy7ulGwBam/T0a3MuAEDzcUYIAABYFkEIAABYFkEIAABYFkEIAABYFkEIAABYliWC0IoVK9SjRw/5+fkpKipKu3btaumWAADANeC6D0Lr169Xamqq5s+frz179mjAgAGKjY1VRUVFS7cGAABa2HX/HKHnn39ekyZN0sMPPyxJysrK0ubNm/XKK69o9uzZLdwdvlNue2iPu+YBALS06zoI1dXVqbi4WHPmzDHXeXp6KiYmRgUFBefV19bWqra21nxdVVUlSXI6nVenwbO2dUXTyH39XdKu0rdb5pEusW83ychw31xn/VcKAK45TZ/bhmFcvNi4jn3xxReGJGPnzp0u62fMmGEMHTr0vPr58+cbklhYWFhYWFiug+Xo0aMXzQrX9Rmh5pozZ45SU1PN142NjTp58qQ6duwoDw+P8+qdTqfCwsJ09OhRBQYGfpet4hJwfK59HKNrH8fo2sbxuTDDMPTf//5XoaGhF629roNQp06d5OXlpfLycpf15eXlstvt59X7+vrK19fXZV1QUNBFtxMYGMh/AK9hHJ9rH8fo2scxurZxfM5ns9kuqe66vmvMx8dHQ4YMUV5enrmusbFReXl5io6ObsHOAADAteC6PiMkSampqZo4caIiIyM1dOhQvfjii6qurjbvIgMAANZ13QehcePG6cSJE0pLS5PD4dDAgQOVk5OjkJCQK57b19dX8+fPP+/rNFwbOD7XPo7RtY9jdG3j+Fw5D8O4lHvLAAAArj/X9TVCAAAA34YgBAAALIsgBAAALIsgBAAALIsgdJlWrFihHj16yM/PT1FRUdq1a1dLt2RZGRkZuummm9S+fXt17txZcXFxKi0tdampqalRUlKSOnbsqHbt2mns2LHnPWgT341nn31WHh4eSklJMddxfFreF198oV/84hfq2LGj/P391a9fP+3evdscNwxDaWlp6tKli/z9/RUTE6PDhw+3YMfW0dDQoKeeekrh4eHy9/fX97//fT399NMuv6PF8bl8BKHLsH79eqWmpmr+/Pnas2ePBgwYoNjYWFVUVLR0a5a0fft2JSUl6YMPPlBubq7q6+s1atQoVVdXmzXTpk3TW2+9pQ0bNmj79u06fvy47rvvvhbs2pqKior0u9/9Tv3793dZz/FpWadOndLNN9+sNm3a6O2339ZHH32kJUuWqEOHDmZNZmamli1bpqysLBUWFiogIECxsbGqqalpwc6tYfHixVq5cqWWL1+ugwcPavHixcrMzNRLL71k1nB8roAbftvUcoYOHWokJSWZrxsaGozQ0FAjIyOjBbtCk4qKCkOSsX37dsMwDKOystJo06aNsWHDBrPm4MGDhiSjoKCgpdq0nP/+979GRESEkZuba9x6663G1KlTDcPg+FwLZs2aZYwYMeIbxxsbGw273W4899xz5rrKykrD19fX+Otf//pdtGhpY8aMMR555BGXdffdd5+RkJBgGAbH50pxRqiZ6urqVFxcrJiYGHOdp6enYmJiVFBQ0IKdoUlVVZUkKTg4WJJUXFys+vp6l2PWq1cvdevWjWP2HUpKStKYMWNcjoPE8bkWvPnmm4qMjNTPfvYzde7cWYMGDdLvf/97c7ysrEwOh8PlGNlsNkVFRXGMvgPDhw9XXl6ePv74Y0nSv/71L73//vu66667JHF8rtR1/2Rpd/vPf/6jhoaG855MHRISokOHDrVQV2jS2NiolJQU3Xzzzerbt68kyeFwyMfH57wf0A0JCZHD4WiBLq3ntdde0549e1RUVHTeGMen5X366adauXKlUlNT9eSTT6qoqEiPP/64fHx8NHHiRPM4XOh/9zhGV9/s2bPldDrVq1cveXl5qaGhQYsWLVJCQoIkcXyuEEEI15WkpCTt379f77//fku3gv/f0aNHNXXqVOXm5srPz6+l28EFNDY2KjIyUs8884wkadCgQdq/f7+ysrI0ceLEFu4Or7/+utauXat169bpRz/6kUpKSpSSkqLQ0FCOjxvw1VgzderUSV5eXufd0VJeXi673d5CXUGSkpOTlZ2drX/84x/q2rWrud5ut6uurk6VlZUu9Ryz70ZxcbEqKio0ePBgeXt7y9vbW9u3b9eyZcvk7e2tkJAQjk8L69Kli/r06eOyrnfv3jpy5IgkmceB/91rGTNmzNDs2bMVHx+vfv36acKECZo2bZoyMjIkcXyuFEGomXx8fDRkyBDl5eWZ6xobG5WXl6fo6OgW7My6DMNQcnKyNm7cqK1btyo8PNxlfMiQIWrTpo3LMSstLdWRI0c4Zt+BO+64Q/v27VNJSYm5REZGKiEhwfw3x6dl3Xzzzec9cuLjjz9W9+7dJUnh4eGy2+0ux8jpdKqwsJBj9B04c+aMPD1dP669vLzU2NgoieNzxVr6au3W6LXXXjN8fX2N1atXGx999JExefJkIygoyHA4HC3dmiU99thjhs1mM7Zt22Z8+eWX5nLmzBmz5tFHHzW6detmbN261di9e7cRHR1tREdHt2DX1nb2XWOGwfFpabt27TK8vb2NRYsWGYcPHzbWrl1rtG3b1nj11VfNmmeffdYICgoy/v73vxt79+41fvrTnxrh4eHGV1991YKdW8PEiRON733ve0Z2drZRVlZmvPHGG0anTp2MmTNnmjUcn8tHELpML730ktGtWzfDx8fHGDp0qPHBBx+0dEuWJemCy5/+9Cez5quvvjJ+/etfGx06dDDatm1r3HvvvcaXX37Zck1b3LlBiOPT8t566y2jb9++hq+vr9GrVy9j1apVLuONjY3GU089ZYSEhBi+vr7GHXfcYZSWlrZQt9bidDqNqVOnGt26dTP8/PyMG2+80Zg7d65RW1tr1nB8Lp+HYZz1aEoAAAAL4RohAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWQQhAABgWf8f/lhR7QEDg0MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fr_sentences = []\n",
    "en_sentences = []\n",
    "\n",
    "with open(config.dataset_path) as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    for line in lines:\n",
    "        line_split = line.split('\\t')\n",
    "        if len(line_split) == 2:\n",
    "            fr_sentences.append(line_split[1].strip())\n",
    "            en_sentences.append(line_split[0].strip())\n",
    "\n",
    "dataset_size = len(en_sentences)\n",
    "distinct_fr_sentences = len(set(fr_sentences))\n",
    "distinct_en_sentences = len(set(en_sentences))\n",
    "\n",
    "fr_distinct_percentage = (distinct_fr_sentences * 100) // dataset_size\n",
    "en_distinct_percentage = (distinct_en_sentences * 100) // dataset_size\n",
    "\n",
    "\n",
    "print(f\"Dataset size is {dataset_size}\")\n",
    "print(f\"Number of unique french sentences is {distinct_fr_sentences} which is {fr_distinct_percentage}%\")\n",
    "print(f\"Number of unique english sentences is {distinct_en_sentences} which is {en_distinct_percentage}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Token distribution\n",
    "fr_tokens_len = [len(fr_tokenizer.encode(sentence).ids) for sentence in fr_sentences]\n",
    "en_tokens_len = [len(en_tokenizer.encode(sentence).ids) for sentence in en_sentences]\n",
    "\n",
    "print(f\"Max token length for french sentences is {max(fr_tokens_len)}\")\n",
    "print(f\"Max token length for english sentences is {max(en_tokens_len)}\")\n",
    "\n",
    "plt.hist([en_tokens_len, fr_tokens_len], color=['r', 'b'], label=['english', 'french'], alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "del fr_sentences\n",
    "del en_sentences\n",
    "del distinct_fr_sentences\n",
    "del distinct_en_sentences\n",
    "del dataset_size\n",
    "del fr_distinct_percentage\n",
    "del en_distinct_percentage\n",
    "del fr_tokens_len\n",
    "del en_tokens_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a21b3",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "* only 69% of the english sentences are distincts. We need to be careful when creating the validation and test sets.\n",
    "* We will set the max token length for french sentences to **120**.\n",
    "* We will set the max token length for english sentences to **60**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a905a",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "Here we will split the dataset into three sets: training, validation and test set. The test and validation set will represent each **10%** of the unique sentences and the training set will represent the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prng_main_key, data_preparation_prng = jax.random.split(prng_main_key, 2)\n",
    "train_loader, val_loader, test_loader = load_and_prepare_dataset(en_tokenizer, \n",
    "                                                                 fr_tokenizer,\n",
    "                                                                 config.dataset_path, \n",
    "                                                                 data_preparation_prng, \n",
    "                                                                 num_epochs=config.training_epochs, \n",
    "                                                                 train_batch_size=config.batch_size, \n",
    "                                                                 test_or_val_batch_size=config.batch_size,\n",
    "                                                                 max_src_len=config.max_src_len,\n",
    "                                                                 max_trg_len=config.max_trg_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1c32a",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "For this tutorial, we want to implement from scratch the [original transformer model](https://arxiv.org/abs/1706.03762) with Jax.\n",
    "<!-- ![Model architecture](https://arxiv.org/html/1706.03762v7/Figures/ModalNet-21.png) -->\n",
    "\n",
    "In this tutorial, we will focus on the implementation part. We will start our journey with the positional encoding component.\n",
    "\n",
    "## Positional encoding\n",
    "The positional encoding module is the module that add encode the position of the word in the model. Same as the original paper, we will use a static positonal encoding computed based on the following formular:\n",
    "\n",
    "***TODO: Add an image of the formular.***\n",
    "\n",
    "## Multi-head attention module\n",
    "\n",
    "The central piece of the multi-heat attention layer is the scaled dot product attention.\n",
    "\n",
    "## Feed-forward component\n",
    "The Feed forward component consists of two linear transformations with a ReLU activation function in between. We will create a module for that as well.\n",
    "\n",
    "## Add&Norm module\n",
    "This layer takes as input the output of a sub layer and a residual connection. It applies a dropout to the output of the previous sublayer and add that to the residual connection. It finally normalizes the result. We will a layer normalization module here instead of the batch naormalization layer used in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0467b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model components\n",
    "\n",
    "test_num_heads = 8\n",
    "test_d_proj = 32\n",
    "test_use_causal_mask= True\n",
    "test_emb_dim = 256\n",
    "test_src_len= 60\n",
    "test_batch_size = 32\n",
    "test_d_inner = 1024\n",
    "test_dropout = 0.2\n",
    "test_num_blocks = 6\n",
    "test_ff_d_inner = 512\n",
    "test_max_vocab_size = 5000\n",
    "max_seq_len = 64\n",
    "\n",
    "test_prng_key = jax.random.key(44)\n",
    "key_1, key_2, key_3, key_4, key_5, dropout_key = jax.random.split(test_prng_key, 6)\n",
    "\n",
    "\n",
    "# Test the positional encoding module\n",
    "test_random_input = jax.random.normal(test_prng_key, (config.batch_size, config.max_trg_len, config.emb_dim))\n",
    "\n",
    "test_pos_enc_module = PositionalEncoding(config.emb_dim, config.max_trg_len)\n",
    "variables = test_pos_enc_module.init(test_prng_key, test_random_input)\n",
    "x = test_pos_enc_module.apply({}, test_random_input)\n",
    "\n",
    "# Expect the input shape to be the same as the output shape\n",
    "print(\"Testing positional encoding module\")\n",
    "print(f\"Input shape: {test_random_input.shape}\")\n",
    "print(f\"Output shape: {x.shape}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Test multi head attention layer shape output\n",
    "test_multi_head_att_module = MultiHeadAttentionModule(test_num_heads, \n",
    "                                                      test_emb_dim, \n",
    "                                                      test_d_proj, \n",
    "                                                      test_d_proj, \n",
    "                                                      use_causal_mask=True)\n",
    "k = jax.random.normal(key_1, (test_batch_size, test_src_len, test_emb_dim))\n",
    "v = jax.random.normal(key_2, (test_batch_size, test_src_len, test_emb_dim))\n",
    "q = jax.random.normal(key_3, (test_batch_size, test_src_len, test_emb_dim))\n",
    "sample_mask = jax.random.choice(key_3, 2, (test_batch_size, test_src_len))\n",
    "\n",
    "variables = test_multi_head_att_module.init(test_prng_key, k, v, q)\n",
    "params = variables['params']\n",
    "\n",
    "attentions = test_multi_head_att_module.apply({'params': params}, k, v, q, mask=sample_mask)\n",
    "print(\"Testing multi head attention module\")\n",
    "print(f\"Expected shape: {(test_batch_size, test_src_len, test_emb_dim)}\")\n",
    "print(f\"Actual shape: {attentions.shape}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Test Feedforward module\n",
    "sample_input = jax.random.normal(key_1, (test_batch_size, test_src_len, test_emb_dim))\n",
    "\n",
    "test_ff_module = FeedForwardModule(test_d_inner, test_emb_dim)\n",
    "variables = test_ff_module.init(key_2, sample_input)\n",
    "\n",
    "test_output = test_ff_module.apply(variables, sample_input)\n",
    "print(\"Testing Feedforward module\")\n",
    "print(f\"Expected output shape: {(test_batch_size, test_src_len, test_emb_dim)}\")\n",
    "print(f\"Actual output shape: {test_output.shape}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Test Add&Norm module\n",
    "sample_x = jax.random.normal(key_1, (test_batch_size, test_src_len, test_emb_dim))\n",
    "sample_residual_x = jax.random.normal(key_2, (test_batch_size, test_src_len, test_emb_dim))\n",
    "\n",
    "test_add_norm_module = AddAndNormModule(test_dropout)\n",
    "variables = test_add_norm_module.init(key_3, sample_x, sample_residual_x, training=True)\n",
    "\n",
    "test_output = test_add_norm_module.apply(variables, \n",
    "                                         sample_x, \n",
    "                                         sample_residual_x, \n",
    "                                         training=True, \n",
    "                                         rngs={'dropout': dropout_key})\n",
    "print(\"Testing Add&Norm module\")\n",
    "print(f\"Expected output shape: {(test_batch_size, test_src_len, test_emb_dim)}\")\n",
    "print(f\"Actual output shape: {test_output.shape}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Test Encoder block module \n",
    "sample_mask = jax.random.choice(key_1, 2, (test_batch_size, test_src_len))\n",
    "sample_x = jax.random.normal(key_2, (test_batch_size, test_src_len, test_emb_dim))\n",
    "\n",
    "test_encoder_block_module = EncoderBlockModule(test_d_inner, test_emb_dim, \n",
    "                                               test_dropout, test_num_heads, test_d_proj)\n",
    "variables = test_encoder_block_module.init(key_3, sample_x)\n",
    "test_output = test_encoder_block_module.apply(variables, sample_x, \n",
    "                                              mask=sample_mask, training=True, \n",
    "                                              rngs={'dropout': dropout_key})\n",
    "print(\"Testing Encoder block module\")\n",
    "print(f\"Expected output shape: {(test_batch_size, test_src_len, test_emb_dim)}\")\n",
    "print(f\"Actual output shape: {test_output.shape}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Test Decoder block module \n",
    "sample_mask = jax.random.choice(key_1, 2, (test_batch_size, test_src_len))\n",
    "sample_x = jax.random.normal(key_2, (test_batch_size, test_src_len, test_emb_dim))\n",
    "sample_enc_output = jax.random.normal(key_3, (test_batch_size, test_src_len, test_emb_dim))\n",
    "\n",
    "test_decoder_block_module = DecoderBlockModule(test_d_inner, test_emb_dim, \n",
    "                                               test_dropout, test_num_heads, test_d_proj)\n",
    "variables = test_decoder_block_module.init(key_4, sample_x, sample_enc_output)\n",
    "test_output = test_decoder_block_module.apply(variables, sample_x, sample_enc_output, \n",
    "                                              mask=sample_mask, training=True, \n",
    "                                              rngs={'dropout': dropout_key})\n",
    "print(\"Testing Decoder block module\")\n",
    "print(f\"Expected output shape: {(test_batch_size, test_src_len, test_emb_dim)}\")\n",
    "print(f\"Actual output shape: {test_output.shape}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Test transformer output shape\n",
    "sample_enc_mask = jax.random.choice(key_1, 2, (test_batch_size, test_src_len))\n",
    "sample_dec_mask = jax.random.choice(key_2, 2, (test_batch_size, test_src_len))\n",
    "sample_enc_x = jax.random.choice(key_3, test_max_vocab_size, (test_batch_size, test_src_len))\n",
    "sample_dec_x = jax.random.choice(key_4, test_max_vocab_size, (test_batch_size, test_src_len))\n",
    "\n",
    "test_transformer_module = TransformerModule(test_num_blocks, test_ff_d_inner, \n",
    "                                            test_emb_dim, test_dropout, \n",
    "                                            test_num_heads, test_d_proj, \n",
    "                                            test_max_vocab_size, max_seq_len)\n",
    "variables = test_transformer_module.init(key_5, sample_enc_x, sample_dec_x)\n",
    "test_output = test_transformer_module.apply(variables, sample_enc_x, sample_dec_x, \n",
    "                                            sample_enc_mask, sample_dec_mask, \n",
    "                                            training=True, rngs={'dropout': dropout_key})\n",
    "\n",
    "print(\"Testing Full transformer module\")\n",
    "print(f\"Expected output shape: {(test_batch_size, test_src_len, test_max_vocab_size)}\")\n",
    "print(f\"Actual output shape: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5383d5",
   "metadata": {},
   "source": [
    "# Training\n",
    "## Visualize learning rate\n",
    "We have a learning rate decay function that slowly warm up the learning rate to a base learning rate and then applies cosine decay to it for the rest of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1259e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_lr=0.01\n",
    "warmup_epochs=2\n",
    "cosine_epochs=8\n",
    "steps_per_epochs=1000\n",
    "\n",
    "steps = list(range(10000))\n",
    "scheduler = create_learning_rate_scheduler(base_lr, warmup_epochs, \n",
    "                                           cosine_epochs, steps_per_epochs)\n",
    "lr_val = [scheduler(step) for step in range(10000)]\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12, 4))\n",
    "ax.plot(steps, lr_val)\n",
    "ax.grid()\n",
    "ax.set(xlabel='Steps', ylabel='Learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07687cf0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9477bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_train_step = jax.pmap(train_step, axis_name=\"batch\", donate_argnums=(0,))\n",
    "parallel_eval_step = jax.pmap(eval_step, axis_name=\"batch\")\n",
    "\n",
    "def train_and_evaluate(param_init_prng_key, dropout_key, config, train_loader, val_loader):\n",
    "    writer = metric_writers.create_default_writer(config.metric_path)\n",
    "    ckp_options = ocp.CheckpointManagerOptions(max_to_keep=3, \n",
    "                                               save_interval_steps=1, \n",
    "                                               best_fn= lambda metrics: metrics['acc'])\n",
    "    ckp_mngr = ocp.CheckpointManager(os.path.abspath(config.checkpoint_path), options=ckp_options)\n",
    "\n",
    "    train_loader_iter = iter(train_loader)\n",
    "    state = create_train_state(config, param_init_prng_key, dropout_key)\n",
    "\n",
    "    # Replicate the train state for pmap\n",
    "    state = flax.jax_utils.replicate(state)\n",
    "    state = state.replace(dropout_key=shard_prng_key(dropout_key))\n",
    "    \n",
    "    for epoch in range(config.training_epochs):\n",
    "        print(f\"\\nTraining Epoch {epoch + 1}\\n\")\n",
    "        acc_vals = jnp.array([])\n",
    "        loss_vals = jnp.array([])\n",
    "        with tqdm(total=config.steps_per_epochs, desc=f\"Training Epoch {epoch}\", leave=False) as progress_bar_train:\n",
    "            for step in tqdm(range(config.steps_per_epochs)):\n",
    "                train_batch = next(train_loader_iter)\n",
    "                train_batch = shard(train_batch)\n",
    "                \n",
    "                state, batch_metrics = parallel_train_step(state, train_batch)\n",
    "                acc_vals = jnp.concatenate([acc_vals, batch_metrics['acc'][:1]])\n",
    "                loss_vals = jnp.concatenate([loss_vals, batch_metrics['loss'][:1]])\n",
    "                progress_bar_train.update(1)\n",
    "\n",
    "            for step in range(config.steps_per_epochs):\n",
    "                writer.write_scalars(step, {'acc': acc_vals[step], 'loss': loss_vals[step]})\n",
    "            progress_bar_train.write(f\"Training Epoch {epoch} End => accuracy: {batch_metrics['acc'][0]}    Loss: {batch_metrics['loss'][0]}\")\n",
    "\n",
    "        print(f\"\\nEval epoch {epoch + 1}\")\n",
    "        eval_acc_vals = jnp.array([])\n",
    "        eval_loss_vals = jnp.array([])\n",
    "        val_loader_iter = iter(val_loader)\n",
    "        with tqdm(total=config.val_steps, desc=f\"Validation Epoch {epoch}\", leave=False) as progress_bar_validation:\n",
    "            for val_step in tqdm(range(config.val_steps)):\n",
    "                val_batch = next(val_loader_iter)\n",
    "                val_batch = shard(val_batch)\n",
    "                \n",
    "                val_metrics = parallel_eval_step(state, val_batch)\n",
    "                eval_acc_vals = jnp.concatenate([eval_acc_vals, val_metrics['acc'][:1]])\n",
    "                eval_loss_vals = jnp.concatenate([eval_loss_vals, val_metrics['loss'][:1]])\n",
    "                progress_bar_validation.update(1)\n",
    "            progress_bar_validation.write(f\"Validation Epoch {epoch + 1} => accuracy: {jnp.mean(eval_acc_vals)}    Loss: {jnp.mean(eval_loss_vals)}\")\n",
    "\n",
    "        ckp_mngr.save(epoch,\n",
    "              args=ocp.args.StandardSave(flax.jax_utils.unreplicate(state)),\n",
    "              metrics={'acc': float(jnp.mean(eval_acc_vals)), 'loss': float(jnp.mean(eval_loss_vals))})\n",
    "    \n",
    "    ckp_mngr.wait_until_finished()\n",
    "    \n",
    "    return state\n",
    "\n",
    "\n",
    "state = train_and_evaluate(param_init_prng_key, dropout_key, config, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6243b3",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b802e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tokenizer = ByteLevelBPETokenizer(config.trg_tokenizer_path + '/vocab.json', config.trg_tokenizer_path + '/merges.txt')\n",
    "en_tokenizer = ByteLevelBPETokenizer(config.src_tokenizer_path + '/vocab.json', config.src_tokenizer_path + '/merges.txt')\n",
    "fr_tokenizer.add_special_tokens(config.tokenizer_special_tokens)\n",
    "en_tokenizer.add_special_tokens(config.tokenizer_special_tokens)\n",
    "\n",
    "model = create_model(config)\n",
    "ckp_options = ocp.CheckpointManagerOptions(max_to_keep=3, \n",
    "                                       save_interval_steps=1, \n",
    "                                       best_fn= lambda metrics: metrics['acc'])\n",
    "ckp_mngr = ocp.CheckpointManager('/kaggle/input/result/results/checkpoints', options=ckp_options)\n",
    "restored_state = ckp_mngr.restore(step=None, args=ocp.args.StandardRestore())\n",
    "\n",
    "# Test\n",
    "src_sentence = 'Thank God'\n",
    "translation_text = run_inference(src_sentence, config, model, restored_state['params'], en_tokenizer, fr_tokenizer)\n",
    "print(translation_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecc733",
   "metadata": {},
   "source": [
    "## Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sentences = []\n",
    "fr_translations = []\n",
    "for sample in test_loader:\n",
    "    for idx in range(sample['src_tokens'].shape[0]):\n",
    "        en_sentence = en_tokenizer.decode(sample['src_tokens'][idx])\n",
    "        fr_translation = fr_tokenizer.decode(sample['trg_input_tokens'][idx])\n",
    "        # model_translation = run_inference(original_sentence, config, model, restored_state['params'], en_tokenizer, fr_tokenizer)\n",
    "        en_sentences.append(en_sentence)\n",
    "        fr_translations.append(fr_translation)\n",
    "        # model_translations.append(model_translation)\n",
    "\n",
    "# Randomnly pick 200 sentences for BLEU score computation\n",
    "indices = jax.random.choice(prng_main_key, len(en_sentences), (200,))\n",
    "bleu_en_sentences = [en_sentences[x] for x in indices]\n",
    "bleu_fr_original_transaltion = [fr_translations[x] for x in indices]\n",
    "model_translations = []\n",
    "for idx in range(200):\n",
    "    translation = run_inference(bleu_en_sentences[idx], config, model, restored_state['params'], en_tokenizer, fr_tokenizer)\n",
    "    model_translations.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [x.split() for x in model_translations]\n",
    "references = [x.split() for x in bleu_fr_original_transaltion]\n",
    "bleu_scores = []\n",
    "\n",
    "\n",
    "for idx in range(200):\n",
    "    score = nltk.translate.bleu_score.sentence_bleu([references[idx]], candidates[idx])\n",
    "    bleu_scores.append(score)\n",
    "bleu_score = sum(bleu_scores) / len(bleu_scores)\n",
    "print(bleu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe3eacb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
